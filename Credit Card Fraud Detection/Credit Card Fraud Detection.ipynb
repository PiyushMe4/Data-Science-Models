import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc
from imblearn.over_sampling import SMOTE

sns.set(style="whitegrid")

df = pd.read_csv("creditcard.csv")
print("Data shape:", df.shape)
df.head()

df['Amount'] = StandardScaler().fit_transform(df[['Amount']])
df = df.drop(['Time'], axis=1)

X = df.drop('Class', axis=1)
y = df['Class']

print("Original class distribution:")
print(y.value_counts())

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("\nResampled class distribution:")
print(pd.Series(y_resampled).value_counts())

X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]  

train_df = pd.DataFrame(X_resampled, columns=X.columns)
train_df['Class'] = y_resampled.values
train_df.to_csv('training_dataset.csv', index=False)
print("Saved: 'training_dataset.csv' with SMOTE-resampled training data")

test_df = X_test.copy()
test_df['True_Class'] = y_test.values
test_df['Predicted_Class'] = y_pred
test_df['Fraud_Probability'] = y_proba
test_df.to_csv('test_dataset.csv', index=False)
print("Saved: 'test_dataset.csv' with test predictions and fraud probability")

fraud_df = test_df[(test_df['True_Class'] == 1) | (test_df['Predicted_Class'] == 1)]
fraud_df.to_csv('fraud_cases_only.csv', index=False)
print("Saved: 'fraud_cases_only.csv' containing actual or predicted frauds only")

y_pred = model.predict(X_test)
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

probs = model.predict_proba(X_test)[:, 1]
precision, recall, _ = precision_recall_curve(y_test, probs)
prc_auc = auc(recall, precision)

plt.plot(recall, precision, label=f'AUPRC = {prc_auc:.4f}')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.grid(True)
plt.show()

df['Predicted_Class'] = model.predict(X)
df[['Amount', 'Class', 'Predicted_Class']].head(10)

import joblib

joblib.dump(model, 'credit_fraud_model.pkl')
print("Model saved as 'credit_fraud_model.pkl'")

df['Predicted_Class'] = model.predict(X)
df['Fraud_Probability'] = model.predict_proba(X)[:, 1]
df[['Amount', 'Class', 'Predicted_Class', 'Fraud_Probability']].to_csv('all_predictions_with_probabilities.csv', index=False)
print("Saved all predictions with probabilities to 'all_predictions_with_probabilities.csv'")

fig, ax = plt.subplots(1, 2, figsize=(10, 5))

sns.countplot(x=y, ax=ax[0], color='purple')
ax[0].set_title('Original Class Distribution')
ax[0].set_xlabel('Class')
ax[0].set_ylabel('Count')

sns.countplot(x=y_resampled, ax=ax[1], color='lightgreen')
ax[1].set_title('SMOTE Resampled Class Distribution')
ax[1].set_xlabel('Class')
ax[1].set_ylabel('Count')

plt.suptitle('Before and After Resampling', fontsize=14)
plt.tight_layout()
plt.show()

importances = model.feature_importances_
features = X.columns

top_idx = np.argsort(importances)[-10:]
top_features = features[top_idx]
top_importances = importances[top_idx]

plt.figure(figsize=(10, 6))
sns.barplot(x=top_importances, y=top_features, color='skyblue')
plt.title('Top 10 Important Features')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# Confusion matrix with annotations
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='coolwarm', cbar=False,
            xticklabels=['Genuine', 'Fraudulent'], yticklabels=['Genuine', 'Fraudulent'])
plt.title('Confusion Matrix - Test Data')
plt.xlabel('Predicted Class')
plt.ylabel('Actual Class')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(df[df['Class'] == 1]['Fraud_Probability'], bins=30, color='red', label='Actual Frauds', kde=True)
sns.histplot(df[df['Class'] == 0]['Fraud_Probability'], bins=30, color='green', label='Genuine Transactions', kde=True)
plt.title('Distribution of Predicted Fraud Probabilities')
plt.xlabel('Fraud Probability Score')
plt.ylabel('Transaction Count')
plt.legend()
plt.tight_layout()
plt.show()

top_suspicious = test_df.sort_values(by='Fraud_Probability', ascending=False).head(10)
top_suspicious_display = top_suspicious[['Amount', 'True_Class', 'Predicted_Class', 'Fraud_Probability']]

print("Top 10 Most Suspicious Transactions Based on Model:")
top_suspicious_display.reset_index(drop=True, inplace=True)
top_suspicious_display
